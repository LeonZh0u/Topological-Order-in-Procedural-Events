{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"unsupervised_instructions_dependency.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Ceh5sxvlDdu9pZVsaQswpkYajmwAYIET","authorship_tag":"ABX9TyP4CVpjLdwHqOdW/h8XQdb4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"92b47244f6424366bea651608823f32f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_64e3c9d1fea24797b683f66f094f04ca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d9fc488c274b4602b1c0fb7a2659ac03","IPY_MODEL_1a516fa8c8da419dada470e78d876088","IPY_MODEL_6e43060aaf1348d08e16c78418c72e9d"]}},"64e3c9d1fea24797b683f66f094f04ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d9fc488c274b4602b1c0fb7a2659ac03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fbbf551b6bee49adbde31398a8ce5e1b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ddcea8618b645afaf9cc6079f6f4383"}},"1a516fa8c8da419dada470e78d876088":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_282bb1d0808a4bd09c207c246a46adca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d4ef0f79c82643a7ba380f6f4fdb7c74"}},"6e43060aaf1348d08e16c78418c72e9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c57f5d61c48c4e018fb4af47f8a385be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 226k/226k [00:00&lt;00:00, 320kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7645179019e47a49b8e3855f62b359a"}},"fbbf551b6bee49adbde31398a8ce5e1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7ddcea8618b645afaf9cc6079f6f4383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"282bb1d0808a4bd09c207c246a46adca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d4ef0f79c82643a7ba380f6f4fdb7c74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c57f5d61c48c4e018fb4af47f8a385be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7645179019e47a49b8e3855f62b359a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30245db6880444228acfa22eba8c1846":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f2cebf0e45d2466a951e65ac264b3040","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1102c254b9fd431abc2fa5f766fed717","IPY_MODEL_019e9ab84cf24e498df26e647bd8b9a7","IPY_MODEL_148e04db5bf44b3889072f27c68ae0b0"]}},"f2cebf0e45d2466a951e65ac264b3040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1102c254b9fd431abc2fa5f766fed717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_364ddda8ed784623962d142384adff9a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9fe7f7b373a7470b99d743b8c03291ed"}},"019e9ab84cf24e498df26e647bd8b9a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6c46f639a2484aa0ada06695935020b6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42298a4dd55d4781b1f9fcfb24ee4dfe"}},"148e04db5bf44b3889072f27c68ae0b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_988f35c3e8064f6b8905dd4de239ee09","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 741B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c91858d9ff364540ae61a3c929093182"}},"364ddda8ed784623962d142384adff9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9fe7f7b373a7470b99d743b8c03291ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c46f639a2484aa0ada06695935020b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"42298a4dd55d4781b1f9fcfb24ee4dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"988f35c3e8064f6b8905dd4de239ee09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c91858d9ff364540ae61a3c929093182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86f0f9962174454dbd5a6d50a559df75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b9709aec5e248f8ad67c41bfb75fb20","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fc237075fc7446ad822268e7488e548b","IPY_MODEL_587436fbae9d42edaf9c1655007e5057","IPY_MODEL_895d6967e80e497ab7ee1aa4143d6ace"]}},"1b9709aec5e248f8ad67c41bfb75fb20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fc237075fc7446ad822268e7488e548b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3189921709ab4edbbfd9035a43511931","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_387a142a3c484cc69973705c4ba94050"}},"587436fbae9d42edaf9c1655007e5057":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_49ca7d6f6c60499fb2f7307017de985f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9b662fdf7b449c6a544a78fa252be4d"}},"895d6967e80e497ab7ee1aa4143d6ace":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e893c89b4f444e469b497924b24b7d89","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 455k/455k [00:00&lt;00:00, 582kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_43a6661d931642c287df9a23cda22367"}},"3189921709ab4edbbfd9035a43511931":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"387a142a3c484cc69973705c4ba94050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49ca7d6f6c60499fb2f7307017de985f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9b662fdf7b449c6a544a78fa252be4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e893c89b4f444e469b497924b24b7d89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"43a6661d931642c287df9a23cda22367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee8d55ef0cce476cac1ac09550019714":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ce2f92fc799b44c88b5813096991fc9a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1a4e8a560b1447d7b45c41425aaa7812","IPY_MODEL_1160ee44bb47483d984590764a1ba8b4","IPY_MODEL_143a08ea7aba407193911a195345fc5c"]}},"ce2f92fc799b44c88b5813096991fc9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a4e8a560b1447d7b45c41425aaa7812":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_849e1b7b27764e018de98931c0339b3a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d854975cddc1454f9cf7ba5d9fe5aa3f"}},"1160ee44bb47483d984590764a1ba8b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3814cf9e0409425688998e2eafce8286","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d77bde8ff804f3784d09ec309234d76"}},"143a08ea7aba407193911a195345fc5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8b723db25cd448fba25b1a588874dce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 10.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_990f6b26082a4f6693c5db62b172cf19"}},"849e1b7b27764e018de98931c0339b3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d854975cddc1454f9cf7ba5d9fe5aa3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3814cf9e0409425688998e2eafce8286":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d77bde8ff804f3784d09ec309234d76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8b723db25cd448fba25b1a588874dce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"990f6b26082a4f6693c5db62b172cf19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec8109be94394e8b86389659da767995":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_697de97162e94e119a07528a5a53eb44","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e609c9ac535748178e4830094b61746f","IPY_MODEL_cd4f728c66c14167a0ff47e19469d6ff","IPY_MODEL_f4a21dc0fa3140e8970887046c35b3d3"]}},"697de97162e94e119a07528a5a53eb44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e609c9ac535748178e4830094b61746f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05b707c31ef049eba47fefcfdbd92b90","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa740a5079284d5f921c469ed6e5fdbc"}},"cd4f728c66c14167a0ff47e19469d6ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ca24e68bebff42928825ad5a8aba79e0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_61a64815061a4d16b1be34f3dd5f4b5c"}},"f4a21dc0fa3140e8970887046c35b3d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2abb4914cf0c4dc78bf2ea8e27ed7533","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 420M/420M [00:09&lt;00:00, 42.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aaebc48551974df4a16bc44f64de5845"}},"05b707c31ef049eba47fefcfdbd92b90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa740a5079284d5f921c469ed6e5fdbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca24e68bebff42928825ad5a8aba79e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"61a64815061a4d16b1be34f3dd5f4b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2abb4914cf0c4dc78bf2ea8e27ed7533":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aaebc48551974df4a16bc44f64de5845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nRG2cFOl_NAq","executionInfo":{"status":"ok","timestamp":1641777152922,"user_tz":300,"elapsed":617,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"669d7e4e-7e65-431d-f33e-97ade7377c63","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Indenpedent Study\n"]}],"source":["%cd drive/My\\ Drive/Indenpedent\\ Study"]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jhS2qmgAYRu","executionInfo":{"status":"ok","timestamp":1641777155288,"user_tz":300,"elapsed":313,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"729a1cd5-8214-4be9-b3da-3b28c6de0c4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data\ttransformers\t wikihow-goal-step\n","output\tUntitled0.ipynb  wikihow_goal_step_data.zip\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5kVPqBUHRkL","executionInfo":{"status":"ok","timestamp":1641777167017,"user_tz":300,"elapsed":9238,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"2bae886e-1d49-458c-84b9-98de57972490"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 4.2 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 61.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 488 kB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 59.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 64.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertPreTrainedModel, BertModel, AdamW\n","from torch import nn\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n","from transformers.modeling_outputs import  NextSentencePredictorOutput\n","import torch"],"metadata":{"id":"At0LtWah_neI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BertOnlyNSPHead(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.seq_relationship = nn.Linear(config.hidden_size, 2)\n","\n","    def forward(self, pooled_output):\n","        seq_relationship_score = self.seq_relationship(pooled_output)\n","        return seq_relationship_score\n","        \n","class BertForSentenceOrder(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.bert = BertModel(config)\n","        self.cls = BertOnlyNSPHead(config)\n","\n","        # Initialize weights and apply final processing\n","        self.post_init()\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","        **kwargs,\n","    ):\n","        r\"\"\"\n","        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n","            Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair\n","            (see `input_ids` docstring). Indices should be in `[0, 1]`:\n","\n","            - 0 indicates sequence B is a continuation of sequence A,\n","            - 1 indicates sequence B is a random sequence.\n","\n","        Returns:\n","\n","        Example:\n","\n","        ```python\n","        >>> from transformers import BertTokenizer, BertForNextSentencePrediction\n","        >>> import torch\n","\n","        >>> tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","        >>> model = BertForNextSentencePrediction.from_pretrained(\"bert-base-uncased\")\n","\n","        >>> prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n","        >>> next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n","        >>> encoding = tokenizer(prompt, next_sentence, return_tensors=\"pt\")\n","\n","        >>> outputs = model(**encoding, labels=torch.LongTensor([1]))\n","        >>> logits = outputs.logits\n","        >>> assert logits[0, 0] < logits[0, 1]  # next sentence was random\n","        ```\n","        \"\"\"\n","\n","        if \"next_sentence_label\" in kwargs:\n","            warnings.warn(\n","                \"The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\",\n","                FutureWarning,\n","            )\n","            labels = kwargs.pop(\"next_sentence_label\")\n","\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","            output_attentions=output_attentions,\n","            output_hidden_states=output_hidden_states,\n","            return_dict=return_dict,\n","        )\n","\n","        pooled_output = outputs[1]\n","\n","        seq_relationship_scores = self.cls(pooled_output)\n","\n","        next_sentence_loss = None\n","        if labels is not None:\n","            loss_fct = CrossEntropyLoss()\n","            next_sentence_loss = loss_fct(seq_relationship_scores.view(-1, 2), labels.view(-1))\n","\n","        if not return_dict:\n","            output = (seq_relationship_scores,) + outputs[2:]\n","            return ((next_sentence_loss,) + output) if next_sentence_loss is not None else output\n","\n","        return NextSentencePredictorOutput(\n","            loss=next_sentence_loss,\n","            logits=seq_relationship_scores,\n","            hidden_states=outputs.hidden_states,\n","            attentions=outputs.attentions,\n","        )"],"metadata":{"id":"ZoCJtrHsIPor"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSentenceOrder.from_pretrained('bert-base-uncased')\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Indenpedent Study/output/model.pt',map_location=torch.device('cpu')))\n","text = (\"After Abraham Lincoln won the November 1860 presidential election on an \"\n","        \"anti-slavery platform, an initial seven slave states declared their \"\n","        \"secession from the country to form the Confederacy.\")\n","text2 = (\"What\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["92b47244f6424366bea651608823f32f","64e3c9d1fea24797b683f66f094f04ca","d9fc488c274b4602b1c0fb7a2659ac03","1a516fa8c8da419dada470e78d876088","6e43060aaf1348d08e16c78418c72e9d","fbbf551b6bee49adbde31398a8ce5e1b","7ddcea8618b645afaf9cc6079f6f4383","282bb1d0808a4bd09c207c246a46adca","d4ef0f79c82643a7ba380f6f4fdb7c74","c57f5d61c48c4e018fb4af47f8a385be","f7645179019e47a49b8e3855f62b359a","30245db6880444228acfa22eba8c1846","f2cebf0e45d2466a951e65ac264b3040","1102c254b9fd431abc2fa5f766fed717","019e9ab84cf24e498df26e647bd8b9a7","148e04db5bf44b3889072f27c68ae0b0","364ddda8ed784623962d142384adff9a","9fe7f7b373a7470b99d743b8c03291ed","6c46f639a2484aa0ada06695935020b6","42298a4dd55d4781b1f9fcfb24ee4dfe","988f35c3e8064f6b8905dd4de239ee09","c91858d9ff364540ae61a3c929093182","86f0f9962174454dbd5a6d50a559df75","1b9709aec5e248f8ad67c41bfb75fb20","fc237075fc7446ad822268e7488e548b","587436fbae9d42edaf9c1655007e5057","895d6967e80e497ab7ee1aa4143d6ace","3189921709ab4edbbfd9035a43511931","387a142a3c484cc69973705c4ba94050","49ca7d6f6c60499fb2f7307017de985f","a9b662fdf7b449c6a544a78fa252be4d","e893c89b4f444e469b497924b24b7d89","43a6661d931642c287df9a23cda22367","ee8d55ef0cce476cac1ac09550019714","ce2f92fc799b44c88b5813096991fc9a","1a4e8a560b1447d7b45c41425aaa7812","1160ee44bb47483d984590764a1ba8b4","143a08ea7aba407193911a195345fc5c","849e1b7b27764e018de98931c0339b3a","d854975cddc1454f9cf7ba5d9fe5aa3f","3814cf9e0409425688998e2eafce8286","5d77bde8ff804f3784d09ec309234d76","e8b723db25cd448fba25b1a588874dce","990f6b26082a4f6693c5db62b172cf19","ec8109be94394e8b86389659da767995","697de97162e94e119a07528a5a53eb44","e609c9ac535748178e4830094b61746f","cd4f728c66c14167a0ff47e19469d6ff","f4a21dc0fa3140e8970887046c35b3d3","05b707c31ef049eba47fefcfdbd92b90","fa740a5079284d5f921c469ed6e5fdbc","ca24e68bebff42928825ad5a8aba79e0","61a64815061a4d16b1be34f3dd5f4b5c","2abb4914cf0c4dc78bf2ea8e27ed7533","aaebc48551974df4a16bc44f64de5845"]},"id":"i3u3dvUYEGI1","executionInfo":{"status":"ok","timestamp":1641777219112,"user_tz":300,"elapsed":34587,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"f56a200c-9c93-42a8-f5f1-acb58ed259e4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92b47244f6424366bea651608823f32f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30245db6880444228acfa22eba8c1846","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86f0f9962174454dbd5a6d50a559df75","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee8d55ef0cce476cac1ac09550019714","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec8109be94394e8b86389659da767995","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSentenceOrder: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSentenceOrder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSentenceOrder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["instructions = ['Create a sketch on a small piece of paper.',\n","'Prepare to create your mural.',\n","'Prepare your paint.',\n","'Begin with a design.',\n","'Produce a scaled down version of your mural.',\n","'Prepare the wall to be painted.',\n","'After you have primed the surface, measure the wall.',\n","'Paint in the base coat of the background.',\n","'Allow the background and base coats to dry.',\n","'Draw the lines, then fill the appeared section with different repetitive patterns.',\n","'Paint patterns with brushes of suitable size for the particular portion of work you are painting.',\n","'Clean up the lines and shapes.',\n","'Seal the mural.',\n","'Be inspired and it will help you succeed!']\n","goal = 'How to Create a Neopoprealist Art Work'"],"metadata":{"id":"oY68VY4z1ZWC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(instructions[0], instructions[7], return_tensors='pt')\n","inputs.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rptFvQ_EK4v","executionInfo":{"status":"ok","timestamp":1641779729432,"user_tz":300,"elapsed":13,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"45d6d1f9-f12e-431f-b0a1-843c241af67e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["outputs = model(**inputs)\n","outputs.keys()\n","torch.argmax(outputs.logits),outputs.logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZ1VO2INEeUA","executionInfo":{"status":"ok","timestamp":1641779731281,"user_tz":300,"elapsed":6,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"6588a02c-347a-4780-897c-b7c5479c86ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0), tensor([[ 1.9039, -0.6269]], grad_fn=<AddmmBackward0>))"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["from collections import defaultdict\n","import numpy as np\n","\n","k=3 \n","\n","mtx = defaultdict(lambda: defaultdict(float))\n","for i in range(len(instructions)):\n","  tmp = np.array([-10.0 for _ in range(len(instructions))])\n","  for j in range(i+1,min(i+5,len(instructions))):\n","    inputs = tokenizer(goal+\" : \"+instructions[i], goal+\" : \"+instructions[j], return_tensors='pt')\n","    tmp[j] = model(**inputs).logits[0][0].item()\n","  sorted = np.flip(np.sort(tmp))[:k]\n","  for top_k in sorted:\n","    mtx[i][np.where(tmp==top_k)[0][0]]=top_k\n"],"metadata":{"id":"mODaaLJl5jJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mtx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0lciwzH_aYs","executionInfo":{"status":"ok","timestamp":1641779865818,"user_tz":300,"elapsed":310,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"38a12b10-447f-4927-c37d-33b4b5f45609"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(<function __main__.<lambda>>,\n","            {0: defaultdict(float,\n","                         {0: -0.03299893066287041,\n","                          1: 1.0073059797286987,\n","                          2: 1.2647675275802612,\n","                          3: -0.739971935749054,\n","                          4: 1.204954981803894,\n","                          5: 0.8929783701896667,\n","                          6: 0.7953421473503113,\n","                          7: 1.854956030845642,\n","                          8: 2.1802072525024414,\n","                          9: 2.482077121734619,\n","                          10: 1.333250880241394,\n","                          11: 2.096648693084717,\n","                          12: 3.0685482025146484,\n","                          13: 2.3721089363098145}),\n","             1: defaultdict(float,\n","                         {0: 0.34122201800346375,\n","                          1: 0.21857950091362,\n","                          2: 1.014075756072998,\n","                          3: -0.46335482597351074,\n","                          4: 1.8706138134002686,\n","                          5: 0.8676372170448303,\n","                          6: 0.624653160572052,\n","                          7: 1.7015873193740845,\n","                          8: 1.7647455930709839,\n","                          9: 1.683005928993225,\n","                          10: 1.2167167663574219,\n","                          11: 1.311890721321106,\n","                          12: 3.6426925659179688,\n","                          13: 1.9968583583831787}),\n","             2: defaultdict(float,\n","                         {0: -0.3879263401031494,\n","                          1: 0.38132089376449585,\n","                          2: 0.7297948002815247,\n","                          3: -0.9027775526046753,\n","                          4: 0.6506367325782776,\n","                          5: -0.03767452761530876,\n","                          6: 0.0825483649969101,\n","                          7: 1.4992632865905762,\n","                          8: 1.987505316734314,\n","                          9: 1.2393909692764282,\n","                          10: 0.9652013182640076,\n","                          11: 0.9877153038978577,\n","                          12: 2.578207492828369,\n","                          13: 1.7978413105010986}),\n","             3: defaultdict(float,\n","                         {0: 1.1902387142181396,\n","                          1: 1.7980047464370728,\n","                          2: 1.7002708911895752,\n","                          3: -0.20254836976528168,\n","                          4: 1.673765778541565,\n","                          5: 1.3720396757125854,\n","                          6: 1.3373439311981201,\n","                          7: 2.1749024391174316,\n","                          8: 2.491014003753662,\n","                          9: 2.7417075634002686,\n","                          10: 1.8556314706802368,\n","                          11: 2.479632616043091,\n","                          12: 3.218423843383789,\n","                          13: 2.6173007488250732}),\n","             4: defaultdict(float,\n","                         {0: -0.08081761002540588,\n","                          1: -1.1764672994613647,\n","                          2: 0.4641232192516327,\n","                          3: -0.8130325078964233,\n","                          4: 0.0458776094019413,\n","                          5: 0.26928946375846863,\n","                          6: 0.11815731227397919,\n","                          7: 1.3756738901138306,\n","                          8: 1.3552411794662476,\n","                          9: 1.394846796989441,\n","                          10: 0.7889266610145569,\n","                          11: 1.0676759481430054,\n","                          12: 2.866126775741577,\n","                          13: 2.018080472946167}),\n","             5: defaultdict(float,\n","                         {0: 0.24661704897880554,\n","                          1: 0.8413735032081604,\n","                          2: 1.1081973314285278,\n","                          3: -0.7350035309791565,\n","                          4: 0.9683181643486023,\n","                          5: 0.7428886294364929,\n","                          6: 0.36014750599861145,\n","                          7: 1.705826997756958,\n","                          8: 1.8032442331314087,\n","                          9: 1.6997770071029663,\n","                          10: 1.1420046091079712,\n","                          11: 1.2274017333984375,\n","                          12: 2.813788890838623,\n","                          13: 2.092959403991699}),\n","             6: defaultdict(float,\n","                         {0: 0.5351874232292175,\n","                          1: 0.9191095232963562,\n","                          2: 1.1341184377670288,\n","                          3: -0.4121938645839691,\n","                          4: 1.0619558095932007,\n","                          5: 0.6192781925201416,\n","                          6: 0.9784305095672607,\n","                          7: 1.773093819618225,\n","                          8: 1.8584275245666504,\n","                          9: 1.8259683847427368,\n","                          10: 1.2501007318496704,\n","                          11: 1.7416824102401733,\n","                          12: 2.7425341606140137,\n","                          13: 2.214629650115967}),\n","             7: defaultdict(float,\n","                         {0: -0.767863392829895,\n","                          1: 0.00458686426281929,\n","                          2: -0.4815619885921478,\n","                          3: -1.1359494924545288,\n","                          4: 0.08792202174663544,\n","                          5: -0.7245040535926819,\n","                          6: -0.40113377571105957,\n","                          7: 0.6559426188468933,\n","                          8: 1.3202446699142456,\n","                          9: 0.7945356965065002,\n","                          10: -0.020898085087537766,\n","                          11: 0.410878986120224,\n","                          12: 2.0285706520080566,\n","                          13: 1.748617172241211}),\n","             8: defaultdict(float,\n","                         {0: -0.8652265667915344,\n","                          1: 0.16138219833374023,\n","                          2: -0.07197219133377075,\n","                          3: -1.2148774862289429,\n","                          4: 0.0048461295664310455,\n","                          5: -0.3535066545009613,\n","                          6: -0.4756329655647278,\n","                          7: 0.5092028975486755,\n","                          8: 1.0289493799209595,\n","                          9: 0.7401004433631897,\n","                          10: -0.01701345667243004,\n","                          11: 0.35422953963279724,\n","                          12: 1.8898227214813232,\n","                          13: 1.742558240890503}),\n","             9: defaultdict(float,\n","                         {0: -1.0104244947433472,\n","                          1: 0.01118597760796547,\n","                          2: 0.007161829620599747,\n","                          3: -1.40373694896698,\n","                          4: -0.06599220633506775,\n","                          5: -0.2808793783187866,\n","                          6: -0.7321946620941162,\n","                          7: 0.8593834042549133,\n","                          8: 0.9894424080848694,\n","                          9: 0.6092777848243713,\n","                          10: -0.6310396790504456,\n","                          11: 1.2678248882293701,\n","                          12: 2.3094358444213867,\n","                          13: 1.255327582359314}),\n","             10: defaultdict(float,\n","                         {0: -0.25656774640083313,\n","                          1: 0.3127225935459137,\n","                          2: 0.05801405385136604,\n","                          3: -0.8139618039131165,\n","                          4: 0.2587916851043701,\n","                          5: -0.3074195086956024,\n","                          6: 0.04277053847908974,\n","                          7: 1.2311898469924927,\n","                          8: 1.5452567338943481,\n","                          9: 1.6689351797103882,\n","                          10: 0.3436335325241089,\n","                          11: 0.8586798310279846,\n","                          12: 2.523097038269043,\n","                          13: 1.6982375383377075}),\n","             11: defaultdict(float,\n","                         {0: -0.7260370850563049,\n","                          1: 0.427383154630661,\n","                          2: 0.423554390668869,\n","                          3: -1.278482437133789,\n","                          4: 0.2052726000547409,\n","                          5: -0.018432985991239548,\n","                          6: -0.16579905152320862,\n","                          7: 0.9811805486679077,\n","                          8: 1.267891764640808,\n","                          9: 0.22499312460422516,\n","                          10: 0.10803669691085815,\n","                          11: 0.4589865803718567,\n","                          12: 2.115830183029175,\n","                          13: 1.7014447450637817}),\n","             12: defaultdict(float,\n","                         {0: -1.3782382011413574,\n","                          1: -1.6785248517990112,\n","                          2: -0.7621579766273499,\n","                          3: -1.6044334173202515,\n","                          4: -1.0148426294326782,\n","                          5: -1.1111538410186768,\n","                          6: -1.1093647480010986,\n","                          7: -0.5877500176429749,\n","                          8: -0.6438167095184326,\n","                          9: -0.8135119676589966,\n","                          10: -0.8420080542564392,\n","                          11: -0.8156382441520691,\n","                          12: 0.9317438006401062,\n","                          13: 0.8609361052513123}),\n","             13: defaultdict(float,\n","                         {0: -0.7829742431640625,\n","                          1: -0.3676650822162628,\n","                          2: -0.38878053426742554,\n","                          3: -1.0217689275741577,\n","                          4: -0.6864966750144958,\n","                          5: -0.7292578220367432,\n","                          6: -0.8299217224121094,\n","                          7: -0.1887817680835724,\n","                          8: -0.6084700226783752,\n","                          9: -0.29605454206466675,\n","                          10: -0.4355291426181793,\n","                          11: -0.4953111708164215,\n","                          12: 0.647731602191925,\n","                          13: 1.668492078781128})})"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["def reverse_graph(G):\n","    '''Return the reversed graph where g[dst][src]=G[src][dst]'''\n","    g={}\n","    for src in G.keys():\n","        for dst in G[src].keys():\n","            if dst not in g.keys():\n","                g[dst]={}\n","            g[dst][src]=G[src][dst]\n","    return g\n","\n","def build_max(rg,root):\n","    '''Find the max in-edge for every node except for the root.'''\n","    mg = {}\n","    for dst in rg.keys():\n","        if dst==root:\n","            continue\n","        max_ind=-100\n","        max_value = -100\n","        for src in rg[dst].keys():\n","            if rg[dst][src]>=max_value:\n","                max_ind = src\n","                max_value = rg[dst][src]\n","        mg[dst]={max_ind:max_value}\n","    return mg\n","\n","def find_circle(mg):\n","    '''Return the firse circle if find, otherwise return None'''\n","        \n","    for start in mg.keys():\n","        visited=[]\n","        stack = [start]\n","        while stack:\n","            n = stack.pop()\n","            if n in visited:\n","                C = []\n","                while n not in C:\n","                    C.append(n)\n","                    n = list(mg[n].keys())[0]\n","                return C\n","            visited.append(n)\n","            if n in mg.keys():\n","                stack.extend(list(mg[n].keys()))\n","    return None\n","        \n","def chu_liu_edmond(G,root):\n","    ''' G: dict of dict of weights\n","            G[i][j] = w means the edge from node i to node j has weight w.\n","            Assume the graph is connected and there is at least one spanning tree existing in G.\n","        root: the root node, has outgoing edges only.\n","    '''\n","    # reversed graph rg[dst][src] = G[src][dst]\n","    rg = reverse_graph(G)\n","    # root only has out edge\n","    rg[root]={}\n","    # the maximum edge for each node other than root\n","    mg = build_max(rg,root)\n","    \n","    # check if mg is a tree (contains a circle)\n","    C = find_circle(mg)\n","    # if there is no circle, it means mg is what we want\n","    if not C:\n","        return reverse_graph(mg)\n","    # Now consider the nodes in the circle C as one new node vc\n","    all_nodes = G.keys()\n","    vc = max(all_nodes)+1\n","    \n","    #The new graph G_prime with V_prime=V\\C+{vc} \n","    V_prime = list(set(all_nodes)-set(C))+[vc]\n","    G_prime = {}\n","    vc_in_idx={}\n","    vc_out_idx={}\n","    # Now add the edges to G_prime\n","    for u in all_nodes:\n","        for v in G[u].keys():\n","            # First case: if the source is not in the circle, and the dest is in the circle, i.e. in-edges for C\n","            # Then we only keep one edge from each node that is not in C to the new node vc with the largest difference (G[u][v]-list(mg[v].values())[0])\n","            # To specify, for each node u in V\\C, there is an edge between u and vc if and only if there is an edge between u and any node v in C,\n","            # And the weight of edge u->vc = max_{v in C} (G[u][v] - mg[v].values) The second term represents the weight of max in-edge of v.\n","            # Then we record that the edge u->vc is originally the edge u->v with v=argmax_{v in C} (G[u][v] - mg[v].values)\n","            \n","            if (u not in C) and (v in C):\n","                if u not in G_prime.keys():\n","                    G_prime[u]={}\n","                w = G[u][v]-list(mg[v].values())[0]\n","                if (vc not in  G_prime[u]) or (vc in  G_prime[u] and w > G_prime[u][vc]):\n","                    G_prime[u][vc] = w\n","                    vc_in_idx[u] = v\n","            # Second case: if the source is in the circle, but the dest is not in the circle, i.e out-edge for C\n","            # Then we only keep one edge from the new node vc to each node that is not in C\n","            # To specify, for each node v in V\\C, there is an edge between vc and v iff there is an edge between any edge u in C and v.\n","            # And the weight of edge vc->v = max_{u in C} G[u][v] \n","            # Then we record that the edge vc->v originally the edge u->v with u=argmax_{u in C} G[u][v] \n","            elif (u in C) and (v not in C):\n","                if vc not in G_prime.keys():\n","                    G_prime[vc]={}\n","                w = G[u][v]\n","                if (v not in  G_prime[vc]) or (v in  G_prime[vc] and w > G_prime[vc][v]):\n","                    G_prime[vc][v] = w\n","                    vc_out_idx[v] = u\n","            # Third case: if the source and dest are all not in the circle, then just add the edge to the new graph.\n","            elif (u not in C) and (v not in C):\n","                if u not in G_prime.keys():\n","                    G_prime[u]={}\n","                G_prime[u][v] = G[u][v]\n","    # Recursively run the algorihtm on the new graph G_prime\n","    # The result A should be a tree with nodes V\\C+vc, then we just need to break the circle C and plug the subtree into A\n","    # To break the circle, we need to use the in-edge of vc, say u->vc to replace the original selected edge u->v, \n","    # where v was the original edge we recorded in the first case above.\n","    # Then if vc has out-edges, we also need to replace them with the original edges, recorded in the second case above.\n","    A = chu_liu_edmond(G_prime,root)\n","    print(A)\n","    all_nodes_A = list(A.keys())\n","    for src in all_nodes_A:\n","        # The number of out-edges varies, could be 0 or any number <=|V\\C|\n","        if src==vc:\n","            for node_in in A[src].keys():\n","                orig_out = vc_out_idx[node_in]\n","                if orig_out not in A.keys():\n","                    A[orig_out] = {}\n","                A[orig_out][node_in]=G[orig_out][node_in]\n","        else:\n","            for dst in A[src]:\n","                # There must be only one in-edge to vc.\n","                if dst==vc:\n","                    orig_in = vc_in_idx[src]\n","                    A[src][orig_in] = G[src][orig_in]\n","                    del A[src][dst]\n","    del A[vc]\n","    \n","    # Now add the edges from the circle to the result.\n","    # Remember not to include the one with new in-edge\n","    for node in C:\n","        if node != orig_in:\n","            src = list(mg[node].keys())[0]\n","            if src not in A.keys():\n","                A[src] = {}\n","            A[src][node] = mg[node][src]\n","    return A "],"metadata":{"id":"H8RadlhE6E5Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chu_liu_edmond(mtx,0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GSTybN6r9s-0","executionInfo":{"status":"ok","timestamp":1641779872586,"user_tz":300,"elapsed":378,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"1b46a240-03fe-4a38-e0f7-7c8e163f75ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: {17: -0.004968404769897461}, 17: {2: 1.7002708911895752, 4: 1.8706138134002686, 7: 2.1749024391174316, 8: 2.491014003753662, 9: 2.7417075634002686, 10: 1.8556314706802368, 11: 2.479632616043091, 12: 3.6426925659179688, 13: 2.6173007488250732}}\n","{0: {16: -0.2766171097755432}, 16: {2: 1.7002708911895752, 4: 1.8706138134002686, 7: 2.1749024391174316, 8: 2.491014003753662, 9: 2.7417075634002686, 10: 1.8556314706802368, 11: 2.479632616043091, 12: 3.6426925659179688, 13: 2.6173007488250732, 5: 1.3720396757125854}}\n","{0: {15: -0.32777807116508484}, 15: {2: 1.7002708911895752, 7: 2.1749024391174316, 8: 2.491014003753662, 9: 2.7417075634002686, 10: 1.8556314706802368, 11: 2.479632616043091, 13: 2.6173007488250732, 5: 1.3720396757125854, 1: 1.7980047464370728}, 1: {4: 1.8706138134002686, 12: 3.6426925659179688}}\n","{0: {14: -0.5374235659837723}, 1: {4: 1.8706138134002686, 12: 3.6426925659179688}, 14: {2: 1.7002708911895752, 7: 2.1749024391174316, 8: 2.491014003753662, 9: 2.7417075634002686, 10: 1.8556314706802368, 11: 2.479632616043091, 13: 2.6173007488250732, 5: 1.3720396757125854, 1: 1.7980047464370728, 6: 1.3373439311981201}}\n"]},{"output_type":"execute_result","data":{"text/plain":["{0: {3: -0.739971935749054},\n"," 1: {4: 1.8706138134002686, 12: 3.6426925659179688},\n"," 3: {1: 1.7980047464370728,\n","  2: 1.7002708911895752,\n","  5: 1.3720396757125854,\n","  6: 1.3373439311981201,\n","  7: 2.1749024391174316,\n","  8: 2.491014003753662,\n","  9: 2.7417075634002686,\n","  10: 1.8556314706802368,\n","  11: 2.479632616043091,\n","  13: 2.6173007488250732}}"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["%cd /content/drive/My\\ Drive/Indenpedent\\ Study\n","!mkdir data\n","!mkdir output\n","!gdown https://drive.google.com/uc?id=1BEhjc8geCzCREJl2VyTbg9W_TFDz-wVI\n","!unzip wikihow_goal_step_data.zip -d ./data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qs78ZQOW2I7","executionInfo":{"status":"ok","timestamp":1641765901733,"user_tz":300,"elapsed":17462,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"5140624f-8919-45dc-cdab-365a8c425a01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Indenpedent Study\n","mkdir: cannot create directory ‘data’: File exists\n","mkdir: cannot create directory ‘output’: File exists\n","Downloading...\n","From: https://drive.google.com/uc?id=1BEhjc8geCzCREJl2VyTbg9W_TFDz-wVI\n","To: /content/drive/My Drive/Indenpedent Study/wikihow_goal_step_data.zip\n","100% 108M/108M [00:01<00:00, 82.0MB/s]\n","Archive:  wikihow_goal_step_data.zip\n","replace ./data/order/val.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"]}]},{"cell_type":"code","source":["#print out some data\n","%cd /content/drive/My\\ Drive/Indenpedent\\ Study\n","import pandas as pd\n","\n","# Load the dataset into a pandas dataframe.\n","train_df = pd.read_csv(\"./data/order/train.csv\", delimiter=',',header=1, names=['', 'video-id', 'fold-ind', 'ending0', 'ending1', 'startphrase', ' ', 'sent1', 'sent2',  'ending2','gold-source',  'label'])\n","print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))\n","val_df = pd.read_csv(\"./data/order/val.csv\", delimiter=',',header=1, names=['', 'video-id', 'fold-ind', 'ending0', 'ending1', 'startphrase', ' ', 'sent1', 'sent2',  'ending2','gold-source',  'label'])\n","print('Number of validation sentences: {:,}\\n'.format(val_df.shape[0]))\n","\n","train_df.sample(5)\n","val_df.sample(5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":603},"id":"A9jXWnRyXG5S","executionInfo":{"status":"ok","timestamp":1641740733529,"user_tz":300,"elapsed":6133,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"42291741-c2a6-4030-d86e-a5c75e28fa7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Indenpedent Study\n","Number of training sentences: 836,127\n","\n","Number of validation sentences: 3,099\n","\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-54303f98-e904-441e-94ec-e95798139c55\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>video-id</th>\n","      <th>fold-ind</th>\n","      <th>ending0</th>\n","      <th>ending1</th>\n","      <th>startphrase</th>\n","      <th></th>\n","      <th>sent1</th>\n","      <th>sent2</th>\n","      <th>ending2</th>\n","      <th>gold-source</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1986</th>\n","      <td>1988</td>\n","      <td>xxx</td>\n","      <td>1988</td>\n","      <td>xxx</td>\n","      <td>xxx</td>\n","      <td>Role Play on Invisionfree Forums</td>\n","      <td>xxx</td>\n","      <td>Once you've been accepted, create a plot page ...</td>\n","      <td>Create or respond to an open thread, these are...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>84</td>\n","      <td>xxx</td>\n","      <td>84</td>\n","      <td>xxx</td>\n","      <td>xxx</td>\n","      <td>Make Orange Julius</td>\n","      <td>xxx</td>\n","      <td>Enjoy!</td>\n","      <td>Add ice cubes one by one, until ice cubes are ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2179</th>\n","      <td>2181</td>\n","      <td>xxx</td>\n","      <td>2181</td>\n","      <td>xxx</td>\n","      <td>xxx</td>\n","      <td>Make Indoor Halloween Decorations</td>\n","      <td>xxx</td>\n","      <td>Get colored construction paper that matches yo...</td>\n","      <td>Cut out the shapes you want to hang on your wa...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2032</th>\n","      <td>2034</td>\n","      <td>xxx</td>\n","      <td>2034</td>\n","      <td>xxx</td>\n","      <td>xxx</td>\n","      <td>Name a Financial Beneficiary</td>\n","      <td>xxx</td>\n","      <td>Submit your form.</td>\n","      <td>Provide all required information.</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>998</td>\n","      <td>xxx</td>\n","      <td>998</td>\n","      <td>xxx</td>\n","      <td>xxx</td>\n","      <td>Clean a Philips Airfryer</td>\n","      <td>xxx</td>\n","      <td>Unplug the appliance and allow it to cool down...</td>\n","      <td>Pull out the pan from the appliance and lift o...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54303f98-e904-441e-94ec-e95798139c55')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-54303f98-e904-441e-94ec-e95798139c55 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-54303f98-e904-441e-94ec-e95798139c55');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["           video-id  fold-ind  ... ending2 gold-source label\n","1986  1988      xxx      1988  ...     NaN         NaN     0\n","82      84      xxx        84  ...     NaN         NaN     1\n","2179  2181      xxx      2181  ...     NaN         NaN     0\n","2032  2034      xxx      2034  ...     NaN         NaN     1\n","996    998      xxx       998  ...     NaN         NaN     0\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#Find max seq length\n","\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib inline\n","\n","all_len = []\n","\n","for index, row in tqdm(train_df[:10000].iterrows(), total=10000):#df.shape[0]):\n","  topic, sent1, sent2 = row[\"startphrase\"], row[\"sent1\"], row[\"sent2\"]\n","  input_ids = tokenizer.encode(topic+\" : \"+sent1, topic+\" : \"+sent2, add_special_tokens=True, return_tensors = 'pt')\n","  all_len.append(len(input_ids[0]))\n","\n","plt.hist(all_len, density=True, bins=30)  # density=False would make counts\n","plt.ylabel('Counts')\n","plt.xlabel('Seq Length');\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":336},"id":"qxgSOkCRcvuj","executionInfo":{"status":"ok","timestamp":1641740761371,"user_tz":300,"elapsed":16137,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"d92823b3-4c6e-4cc0-cbc4-6c92f1b46c59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 34%|███▍      | 3426/10000 [00:05<00:10, 627.23it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n","100%|██████████| 10000/10000 [00:15<00:00, 637.05it/s]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","import pickle\n","import os\n","from transformers import BertTokenizer\n","\n","class PrecondData(Dataset):\n","\n","  def __init__(self, train_df, val_df):\n","    ''' \"<\" the first sentence is the precondition\n","        \">\" the second sentence is the precondition\n","        \"?\" no obvious dependency information between the two\n","    '''\n","    self.label_dict = {'<': 0, '>': 1, '?': 2}\n","\n","    self.train_df = train_df\n","    self.val_df = val_df\n","\n","    self.base_path = '/content/'\n","    self.tokenizer = tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","    self.train_data = self.load_data(self.train_df)\n","    self.val_data = self.load_data(self.val_df)\n","\n","  def load_data(self, df):\n","    MAX_LEN = 100\n","    token_ids = []\n","    mask_ids = []\n","    seg_ids = []\n","    y = []\n","    startphrases = df['startphrase'].to_list()\n","    sentence1s = df['sent1'].to_list()\n","    sentence2s = df['sent2'].to_list()\n","    labels = df['label'].to_list()\n","\n","    for (topic, sent1, sent2, label) in zip(startphrases, sentence1s, sentence2s, labels):\n","      input1_id = self.tokenizer.encode(topic+\" : \"+sent1, max_length = MAX_LEN, add_special_tokens = False)\n","      input2_id = self.tokenizer.encode(topic+\" : \"+sent2, max_length = MAX_LEN, add_special_tokens = False)\n","      pair_token_ids = [self.tokenizer.cls_token_id] + input1_id + [self.tokenizer.sep_token_id] + input2_id + [self.tokenizer.sep_token_id]\n","      input1_len = len(input1_id)\n","      input2_len = len(input2_id)\n","\n","      segment_ids = torch.tensor([0] * (input1_len + 2) + [1] * (input2_len + 1))  # sentence 0 and sentence 1\n","      attention_mask_ids = torch.tensor([1] * (input1_len + input2_len + 3))  # mask padded values\n","\n","      token_ids.append(torch.tensor(pair_token_ids))\n","      seg_ids.append(segment_ids)\n","      mask_ids.append(attention_mask_ids)\n","      y.append(label)\n","\n","    token_ids = pad_sequence(token_ids, batch_first=True)\n","    mask_ids = pad_sequence(mask_ids, batch_first=True)\n","    seg_ids = pad_sequence(seg_ids, batch_first=True)\n","    y = torch.tensor(y)\n","    dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n","    print(len(dataset))\n","    return dataset\n","\n","  def get_data_loaders(self, batch_size=32, shuffle=True):\n","    train_loader = DataLoader(\n","      self.train_data,\n","      shuffle=shuffle,\n","      batch_size=batch_size\n","      )\n","\n","    val_loader = DataLoader(\n","      self.val_data,\n","      shuffle=shuffle,\n","      batch_size=batch_size\n","      )\n","\n","    return train_loader, val_loader\n","\n","dataset = PrecondData(train_df[:100000], val_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTuzM_7ZiJOu","executionInfo":{"status":"ok","timestamp":1641740931388,"user_tz":300,"elapsed":133729,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"b0e6fc79-fcc7-4664-dc52-e57e5d9ceb85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["100000\n","3099\n"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"DfQpv3lOZ4zc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BertForSentenceOrder.from_pretrained('bert-base-uncased')\n","model.to(device)\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oqizFSDroPoq","executionInfo":{"status":"ok","timestamp":1641741046656,"user_tz":300,"elapsed":13301,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"8a59f832-451f-4a7b-d844-d131c8d77d0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSentenceOrder: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSentenceOrder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSentenceOrder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["def multi_acc(y_pred, y_test):\n","  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test).sum().float() / float(y_test.size(0))\n","  return acc\n","\n","import time\n","\n","EPOCHS = 2\n","\n","def train(model, train_loader, val_loader, optimizer):  \n","  total_step = len(train_loader)\n","\n","  for epoch in range(EPOCHS):\n","    start = time.time()\n","    model.train()\n","    total_train_loss = 0\n","    total_train_acc  = 0\n","    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(tqdm(train_loader)):\n","      optimizer.zero_grad()\n","      pair_token_ids = pair_token_ids.to(device)\n","      mask_ids = mask_ids.to(device)\n","      seg_ids = seg_ids.to(device)\n","      labels = y.to(device)\n","\n","      loss, prediction = model(pair_token_ids, \n","                             token_type_ids=seg_ids, \n","                             attention_mask=mask_ids, \n","                             labels=labels).values()\n","\n","      acc = multi_acc(prediction, labels)\n","\n","      loss.backward()\n","      optimizer.step()\n","      \n","      total_train_loss += loss.item()\n","      total_train_acc  += acc.item()\n","\n","    train_acc  = total_train_acc/len(train_loader)\n","    train_loss = total_train_loss/len(train_loader)\n","    model.eval()\n","    total_val_acc  = 0\n","    total_val_loss = 0\n","    with torch.no_grad():\n","      for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(val_loader):\n","        optimizer.zero_grad()\n","        pair_token_ids = pair_token_ids.to(device)\n","        mask_ids = mask_ids.to(device)\n","        seg_ids = seg_ids.to(device)\n","        labels = y.to(device)\n","        \n","        loss, prediction = model(pair_token_ids, \n","                             token_type_ids=seg_ids, \n","                             attention_mask=mask_ids, \n","                             labels=labels).values()\n","        \n","        acc = multi_acc(prediction, labels)\n","\n","        total_val_loss += loss.item()\n","        total_val_acc  += acc.item()\n","\n","    val_acc  = total_val_acc/len(val_loader)\n","    val_loss = total_val_loss/len(val_loader)\n","    end = time.time()\n","    hours, rem = divmod(end-start, 3600)\n","    minutes, seconds = divmod(rem, 60)\n","\n","    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')\n","    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"],"metadata":{"id":"3h4Na8JlEgbJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader, val_loader = dataset.get_data_loaders()\n","train(model, train_loader, val_loader, optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUcwoJgOpASY","executionInfo":{"status":"ok","timestamp":1641753121656,"user_tz":300,"elapsed":12050681,"user":{"displayName":"Liyang Zhou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcpNcXSMEhNVUkXiTrlN9go9kHm4yQW5NacHS9=s64","userId":"12409476534595626967"}},"outputId":"ccab1274-5d67-4220-9eda-8a2e7ae4e8ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3125/3125 [1:39:47<00:00,  1.92s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: train_loss: 0.5823 train_acc: 0.6799 | val_loss: 0.4284 val_acc: 0.8067\n","01:40:29.89\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3125/3125 [1:39:37<00:00,  1.91s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: train_loss: 0.4316 train_acc: 0.7978 | val_loss: 0.3994 val_acc: 0.8225\n","01:40:20.56\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/Indenpedent Study/output/model.pt\")"],"metadata":{"id":"Qjqt6ielpEyB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"u8UU2YVHZZq0"},"execution_count":null,"outputs":[]}]}